version: "3"

services:
  hadoop-namenode:
    build: ./hadoop
    ports:
      - "9870:9870"
    volumes:
      - ./hadoop/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
    entrypoint: bash -c '/namenode-entrypoint.sh'

  hadoop-datanode:
    build: ./hadoop
    volumes:
      - ./hadoop/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
    command: bash -c '$$HADOOP_HOME/bin/hdfs datanode'

  hadoop-yarn:
    build: yarn
    ports:
      - "8088:8088"
    volumes:
      - ./yarn/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./yarn/yarn-site.xml:/opt/hadoop/etc/hadoop/yarn-site.xml
    command: bash -c 'service ssh start && $$HADOOP_HOME/bin/yarn resourcemanager'

  hadoop-yarn-node-1:
    build: yarn
    volumes:
      - ./yarn/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./yarn/yarn-site.xml:/opt/hadoop/etc/hadoop/yarn-site.xml
    command: bash -c 'service ssh start && $$HADOOP_HOME/bin/yarn nodemanager'

  hadoop-yarn-node-2:
    build: yarn
    volumes:
      - ./yarn/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./yarn/yarn-site.xml:/opt/hadoop/etc/hadoop/yarn-site.xml
    command: bash -c 'service ssh start && $$HADOOP_HOME/bin/yarn nodemanager'

  spark-master:
    build: ./spark
    ports:
      - "8080:8080"
    command: bash -c '$$SPARK_HOME/bin/spark-class org.apache.spark.deploy.master.Master'

  spark-worker:
    build: ./spark
    command: bash -c '$$SPARK_HOME/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077'
